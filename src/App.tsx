import { useState, useRef, useEffect } from "react";
import * as tf from "@tensorflow/tfjs";
import * as mobilenet from "@tensorflow-models/mobilenet";
import "./App.css";

interface ScanResult {
    cardId: string;
    cardName: string;
    similarity: number; // cosine similarity in [0, 100]
    debugImage?: string;
}

interface EmbeddingData {
    card_id: string;
    filename: string;
    embedding: number[];
}

interface EmbeddingsDatabase {
    model: string;
    embedding_dim: number;
    total_images: number;
    total_cards: number;
    embeddings: EmbeddingData[];
}

function App() {
    const [isScanning, setIsScanning] = useState(false);
    const [result, setResult] = useState<ScanResult | null>(null);
    const [error, setError] = useState<string | null>(null);
    const [modelStatus, setModelStatus] = useState<string>("Loading model...");
    const [isModelLoaded, setIsModelLoaded] = useState(false);

    const videoRef = useRef<HTMLVideoElement>(null);
    const canvasRef = useRef<HTMLCanvasElement>(null);
    const streamRef = useRef<MediaStream | null>(null);
    const intervalRef = useRef<number | null>(null);

    // MobileNet model reference
    const modelRef = useRef<mobilenet.MobileNet | null>(null);
    const embeddingsDatabaseRef = useRef<EmbeddingsDatabase | null>(null);

    // üß† Load MobileNet feature extractor + embeddings database
    useEffect(() => {
        async function loadModel() {
            try {
                setModelStatus("Loading embeddings database...");

                // Load embeddings database (generated by TypeScript script)
                const embeddingsResponse = await fetch("/embeddings/embeddings.json");
                const embeddingsData: EmbeddingsDatabase = await embeddingsResponse.json();
                embeddingsDatabaseRef.current = embeddingsData;

                console.log(`‚úÖ Loaded ${embeddingsData.total_images} embeddings for ${embeddingsData.total_cards} cards`);
                console.log(`   Model: ${embeddingsData.model}`);
                console.log(`   Embedding dimension: ${embeddingsData.embedding_dim}`);

                setModelStatus("Loading MobileNet model...");

                // Load MobileNet v2 from TensorFlow.js (same as used for embeddings generation)
                const featureExtractor = await mobilenet.load({
                    version: 2,
                    alpha: 1.0, // Full model (not quantized)
                });
                modelRef.current = featureExtractor;

                console.log("‚úÖ MobileNet v2 loaded successfully");

                setModelStatus(`Model loaded! ${embeddingsData.total_cards} cards ready (${embeddingsData.total_images} variations)`);
                setIsModelLoaded(true);
            } catch (err) {
                console.error("Failed to load model:", err);
                setError("Failed to load model: " + (err as Error).message);
                setModelStatus("Model load failed");
                setIsModelLoaded(false);
            }
        }

        loadModel();
    }, []);

    // üì∏ Start camera and scanning
    const startScanning = async () => {
        if (!modelRef.current) {
            setError("Model not loaded yet. Please wait...");
            return;
        }

        try {
            setError(null);

            // Request camera access
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    facingMode: "environment",
                    width: { ideal: 720 },
                    height: { ideal: 1000 },
                    aspectRatio: { ideal: 0.72 },
                },
            });

            if (videoRef.current) {
                videoRef.current.srcObject = stream;
                streamRef.current = stream;
                setIsScanning(true);

                // Start capturing frames every 500ms
                intervalRef.current = window.setInterval(() => {
                    captureAndPredict();
                }, 500);
            }
        } catch (err) {
            setError("Failed to access camera: " + (err as Error).message);
        }
    };

    // üõë Stop camera and scanning
    const stopScanning = () => {
        if (intervalRef.current) {
            clearInterval(intervalRef.current);
            intervalRef.current = null;
        }

        if (streamRef.current) {
            streamRef.current.getTracks().forEach((track) => track.stop());
            streamRef.current = null;
        }

        if (videoRef.current) {
            videoRef.current.srcObject = null;
        }

        setIsScanning(false);
    };

    // üî¢ Compute cosine similarity between two vectors
    const cosineSimilarity = (a: number[], b: number[]): number => {
        if (a.length !== b.length) {
            throw new Error("Vectors must have same length");
        }

        let dotProduct = 0;
        let normA = 0;
        let normB = 0;

        for (let i = 0; i < a.length; i++) {
            dotProduct += a[i] * b[i];
            normA += a[i] * a[i];
            normB += b[i] * b[i];
        }

        normA = Math.sqrt(normA);
        normB = Math.sqrt(normB);

        if (normA === 0 || normB === 0) {
            return 0;
        }

        return dotProduct / (normA * normB);
    };

    // üîç Find nearest neighbor in embeddings database
    const findNearestCard = (queryEmbedding: number[]): { cardId: string; similarity: number } => {
        if (!embeddingsDatabaseRef.current) {
            throw new Error("Embeddings database not loaded");
        }

        let bestMatch = {
            cardId: "",
            similarity: -1,
        };

        for (const entry of embeddingsDatabaseRef.current.embeddings) {
            const similarity = cosineSimilarity(queryEmbedding, entry.embedding);

            if (similarity > bestMatch.similarity) {
                bestMatch = {
                    cardId: entry.card_id,
                    similarity: similarity,
                };
            }
        }

        return bestMatch;
    };

    // üéØ Capture frame and run embedding extraction + similarity search
    const captureAndPredict = async () => {
        if (!videoRef.current || !canvasRef.current || !modelRef.current) return;

        const video = videoRef.current;
        const canvas = canvasRef.current;
        const context = canvas.getContext("2d");

        if (!context || video.readyState !== video.HAVE_ENOUGH_DATA) return;

        try {
            // MobileNet expects 224√ó224 input
            const TARGET_SIZE = 224;

            // Set canvas to model input size
            canvas.width = TARGET_SIZE;
            canvas.height = TARGET_SIZE;

            const videoWidth = video.videoWidth;
            const videoHeight = video.videoHeight;

            if (!videoWidth || !videoHeight) {
                console.warn("‚ö†Ô∏è videoWidth/videoHeight is zero ‚Äî metadata not ready");
                return;
            }

            // Crop to card aspect ratio first (~0.72:1 like training data 320√ó440)
            const CARD_ASPECT = 320 / 440; // ~0.727
            const videoAspect = videoWidth / videoHeight;

            let sx = 0;
            let sy = 0;
            let sWidth = videoWidth;
            let sHeight = videoHeight;

            if (videoAspect > CARD_ASPECT) {
                // Video is wider ‚Üí crop left/right
                sHeight = videoHeight;
                sWidth = sHeight * CARD_ASPECT;
                sx = (videoWidth - sWidth) / 2;
                sy = 0;
            } else {
                // Video is taller ‚Üí crop top/bottom
                sWidth = videoWidth;
                sHeight = sWidth / CARD_ASPECT;
                sx = 0;
                sy = (videoHeight - sHeight) / 2;
            }

            // Draw cropped card region and resize to 224√ó224
            context.drawImage(video, sx, sy, sWidth, sHeight, 0, 0, TARGET_SIZE, TARGET_SIZE);

            // Convert to tensor and extract embeddings with MobileNet
            const imageData = context.getImageData(0, 0, TARGET_SIZE, TARGET_SIZE);

            const embeddingTensor = tf.tidy(() => {
                // Convert canvas to tensor [224, 224, 3]
                const imageTensor = tf.browser.fromPixels(imageData);

                console.log("Input tensor shape:", imageTensor.shape);

                // Extract embedding using MobileNet's infer method (1024-dim)
                // The second parameter (true) returns embeddings instead of classifications
                const embeddingRaw = modelRef.current!.infer(imageTensor, true) as tf.Tensor;

                console.log("Raw embedding shape:", embeddingRaw.shape);

                // Squeeze to remove batch dimension if present: [1, 1024] -> [1024]
                const embedding = embeddingRaw.squeeze() as tf.Tensor;

                console.log("Squeezed embedding shape:", embedding.shape);
                console.log("Raw embedding sample:", embedding.slice([0], [10]).dataSync());

                // L2 normalize (same as training)
                const norm = tf.norm(embedding, 2, -1, true);
                const normalizedEmbedding = embedding.div(norm).squeeze() as tf.Tensor;

                console.log("Normalized embedding sample:", normalizedEmbedding.slice([0], [10]).dataSync());

                // Return 1D tensor [1024]
                return normalizedEmbedding;
            });

            // Get embedding as array
            const embeddingArray = await embeddingTensor.data();
            const embeddingVector = Array.from(embeddingArray);

            console.log("Embedding vector length:", embeddingVector.length);

            // Find nearest card
            const match = findNearestCard(embeddingVector);

            console.log("üîç Similarity search:", {
                cardId: match.cardId,
                similarity: (match.similarity * 100).toFixed(1) + "%",
                tensors: tf.memory().numTensors,
            });

            // Cleanup
            embeddingTensor.dispose();

            // Update result
            const cardName = match.cardId.split("_").slice(1).join(" ");
            const debugImage = canvas.toDataURL("image/png");

            setResult({
                cardId: match.cardId,
                cardName,
                similarity: match.similarity * 100,
                debugImage,
            });
        } catch (err) {
            console.error("‚ùå Prediction error:", err);
        }
    };

    // üßπ Cleanup on unmount
    useEffect(() => {
        return () => {
            stopScanning();
            // Note: MobileNet doesn't have a dispose method
        };
    }, []);

    return (
        <div className="app">
            <header>
                <h1>üÉè CGP Card Scanner</h1>
                <p>AI-powered instant card recognition (MobileNet v2 embeddings)</p>
                <div className="model-status">{modelStatus}</div>
            </header>

            <main>
                <div className="scanner-container">
                    {/* Video stream */}
                    <div className="video-wrapper">
                        <video ref={videoRef} autoPlay playsInline muted className={isScanning ? "active" : "hidden"} />
                    </div>

                    {/* Hidden canvas for frame capture */}
                    <canvas ref={canvasRef} style={{ display: "none" }} />

                    {/* Control button */}
                    {!isScanning ? (
                        <button onClick={startScanning} className="btn-primary" disabled={!isModelLoaded}>
                            Start Scanner
                        </button>
                    ) : (
                        <button onClick={stopScanning} className="btn-secondary">
                            Stop Scanner
                        </button>
                    )}
                </div>

                {/* Error display */}
                {error && (
                    <div className="error">
                        <strong>Error:</strong> {error}
                    </div>
                )}

                {/* Result display - updates continuously */}
                {result && isScanning && (
                    <div className="result">
                        <div className="result-header">üîÑ Continuous Prediction (Live)</div>
                        <div className="result-content">
                            <div className="card-id">{result.cardId}</div>
                            <div className="card-name">{result.cardName}</div>
                            <div className={"card-meta" + (result.similarity > 80 ? " card-meta--high-confidence" : "")}>
                                <span>Similarity: {result.similarity.toFixed(1)}%</span>
                            </div>

                            {/* Debug: Show the actual image sent to AI */}
                            {result.debugImage && (
                                <div style={{ marginTop: "1rem" }}>
                                    <div
                                        style={{
                                            fontSize: "0.9rem",
                                            color: "#808080",
                                            marginBottom: "0.5rem",
                                        }}>
                                        Image sent to AI (224√ó224):
                                    </div>
                                    <img
                                        src={result.debugImage}
                                        alt="Debug view"
                                        style={{
                                            border: "1px solid #e0e0e0",
                                            borderRadius: "4px",
                                            maxWidth: "200px",
                                            imageRendering: "auto",
                                        }}
                                    />
                                </div>
                            )}
                        </div>
                    </div>
                )}

                {isScanning && !result && (
                    <div className="scanning-indicator">
                        <div className="spinner"></div>
                        <p>Scanning for cards...</p>
                    </div>
                )}
            </main>
        </div>
    );
}

export default App;
